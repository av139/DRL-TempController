# General configuration section
general:
  broker_address: "100.120.27.64"                      # Address of the MQTT broker
  port: 1883                                           # Port for the MQTT server
  temp_topic: "temperature_control/temp_data"          # MQTT topic for temperature data
  pwm_topic: "temperature_control/pwm_control"         # MQTT topic for PWM control
  target_temp_min: 25                                  # Minimum target temperature
  target_temp_max: 45                                  # Maximum target temperature
  algorithm: "A2C"                                     # Algorithm to be used (options: "Random", "Oven" (On-Off), "Fuzzy", "PID", "SAC", "PPO", "DQN", "A2C", "DDPG", "TD3", "TRPO")
  action_space_type: "box"                             # Type of action space, either "box" or "discrete" (Supported by PPO, A2C, TRPO)
  discrete_step: 20                                    # Discrete step size (in %)
  n_eval_episodes: 5                                   # Number of evaluation episodes

# Temperature-related configuration section
temp_config:
  max_diff: 15                                         # Maximum temperature difference / choose target temp max_diff
  temp_tolerance: 0.3                                  # Temperature tolerance (target_temp Â± tolerance)
  critical_range_steps: 50                             # Number of steps within the critical range
  target_temp_range: 5                                 # choose target temp min_diff, see choose_target_temp method
  target_temp_low: 25                                  # Lower bound of target temp, used to define observation space boundaries
  target_temp_high: 45                                 # Upper bound of target temp, used to define observation space boundaries
  actual_temp_low: 15                                  # Lower bound of actual temp, used to define observation space boundaries
  actual_temp_high: 55                                 # Upper bound of actual temp, used to define observation space boundaries
  cooling_temp_low: 15                                 # Lower bound of cooling temp, used to define observation space boundaries
  cooling_temp_high: 55                                # Upper bound of cooling temp, used to define observation space boundaries

# Disturbance configuration section
dist_config:
  dist_max: 10                                         # Upper bound for random disturbance PWM duty cycle values (in %)
  dist_min: 5                                          # Lower bound for random disturbance PWM duty cycle values (in %)
  step_duration: 3                                     # Number of steps each random disturbance value lasts
  chance_of_zero: 0.2                                  # Probability of zero disturbance (20%)

# Random algorithm configuration section
random:
  total_timesteps: 25000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode

# Oven (On-Off Controller) configuration section
oven:
  total_timesteps: 25000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode

# Fuzzy logic controller configuration section
fuzzy:
  total_timesteps: 25000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode

# PID controller configuration section
pid:
  total_timesteps: 25000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode  
  kp: 1.0                                              # Proportional gain for the PID controller
  ki: 0.1                                              # Integral gain for the PID controller
  kd: 0.05                                             # Derivative gain for the PID controller  

# SAC algorithm configuration section
sac:
  total_timesteps: 80000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode
  eval_freq: 5000                                      # Frequency of model evaluation (in steps)
  save_freq: 5000                                      # Frequency of model saving (in steps)
  buffer_size: 1000000                                 # Default: 1000000   # Size of the replay buffer
  learning_rate: 0.0003                                # Default: 0.0003    # Learning rate
  learning_starts: 1000                                # Default: 100       # Number of steps before learning starts (to populate the replay buffer)
  batch_size: 256                                      # Default: 256       # Batch size
  tau: 0.005                                           # Default: 0.005     # Coefficient for soft update
  gamma: 0.99                                          # Default: 0.99      # Discount factor for future rewards
  train_freq: 1                                        # Default: 1         # Frequency of training (in steps)
  gradient_steps: 1                                    # Default: 1         # Number of gradient steps to perform during training
  action_noise: null                                   # Default: null      # Action noise
  replay_buffer_class: null                            # Default: null      # Replay buffer class
  replay_buffer_kwargs: null                           # Default: null      # Replay buffer parameters
  optimize_memory_usage: false                         # Default: false     # Optimize memory usage
  ent_coef: "auto"                                     # Default: "auto"    # Entropy coefficient (auto-tuned if set to "auto")
  target_update_interval: 1                            # Default: 1         # Interval for updating the target network
  target_entropy: "auto"                               # Default: "auto"    # Target entropy
  use_sde: true                                        # Default: false     # Use State Dependent Exploration
  sde_sample_freq: -1                                  # Default: -1        # Sampling frequency for SDE
  use_sde_at_warmup: true                              # Default: false     # Use SDE during warm-up
  stats_window_size: 100                               # Default: 100       # Size of the statistics window
  tensorboard_log: "./tensorboard/"                    # Default: null      # Path to the Tensorboard log
  policy_kwargs: null                                  # Default: null      # Policy parameters
  verbose: 2                                           # Default: 0         # Verbosity level (0: no output, 1: occasional output, 2: all output)
  seed: null                                           # Default: null      # Random seed
  device: "auto"                                       # Default: "auto"    # Device to use (cpu, cuda, auto)

# PPO algorithm configuration section
ppo:
  total_timesteps: 80000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode
  eval_freq: 5000                                      # Frequency of model evaluation (in steps)
  save_freq: 5000                                      # Frequency of model saving (in steps)
  learning_rate: 0.0003                                # Default: 0.0003    # Learning rate
  n_steps: 2048                                        # Default: 2048      # Number of samples to collect before updating the policy
  batch_size: 64                                       # Default: 64        # Batch size
  n_epochs: 10                                         # Default: 10        # Number of optimization epochs per update
  gamma: 0.99                                          # Default: 0.99      # Discount factor
  gae_lambda: 0.95                                     # Default: 0.95      # GAE lambda
  clip_range: 0.2                                      # Default: 0.2       # Clipping range
  clip_range_vf: null                                  # Default: null      # Clipping range for value function
  normalize_advantage: true                            # Default: true      # Normalize advantage function
  ent_coef: 0.0                                        # Default: 0.0       # Entropy coefficient
  vf_coef: 0.5                                         # Default: 0.5       # Value function loss coefficient
  max_grad_norm: 0.5                                   # Default: 0.5       # Maximum gradient norm
  use_sde: false                                       # Default: false     # Use State Dependent Exploration
  sde_sample_freq: -1                                  # Default: -1        # Sampling frequency for SDE
  rollout_buffer_class: null                           # Default: null      # Rollout buffer class
  rollout_buffer_kwargs: null                          # Default: null      # Rollout buffer parameters
  target_kl: null                                      # Default: null      # Target KL divergence
  stats_window_size: 100                               # Default: 100       # Size of the statistics window
  tensorboard_log: "./tensorboard/"                    # Default: null      # Path to the Tensorboard log
  policy_kwargs: null                                  # Default: null      # Policy parameters
  verbose: 2                                           # Default: 0         # Verbosity level (0: no output, 1: occasional output, 2: all output)
  seed: null                                           # Default: null      # Random seed
  device: "auto"                                       # Default: "auto"    # Device to use (cpu, cuda, auto)

# DQN algorithm configuration section
dqn:
  total_timesteps: 80000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode
  eval_freq: 5000                                      # Frequency of model evaluation (in steps)
  save_freq: 5000                                      # Frequency of model saving (in steps)
  learning_rate: 0.0001                                # Default: 0.0001    # Learning rate
  buffer_size: 1000000                                 # Default: 1000000   # Size of the replay buffer
  learning_starts: 100                                 # Default: 100       # Number of steps before learning starts
  batch_size: 32                                       # Default: 32        # Batch size
  tau: 1.0                                             # Default: 1.0       # Coefficient for soft update
  gamma: 0.99                                          # Default: 0.99      # Discount factor
  train_freq: 4                                        # Default: 4         # Frequency of training
  gradient_steps: 1                                    # Default: 1         # Number of gradient steps to perform during training
  replay_buffer_class: null                            # Default: null      # Replay buffer class
  replay_buffer_kwargs: null                           # Default: null      # Replay buffer parameters
  optimize_memory_usage: false                         # Default: false     # Optimize memory usage
  target_update_interval: 10000                        # Default: 10000     # Interval for updating the target network
  exploration_fraction: 0.1                            # Default: 0.1       # Fraction of training steps where exploration is used
  exploration_initial_eps: 1.0                         # Default: 1.0       # Initial exploration rate
  exploration_final_eps: 0.05                          # Default: 0.05      # Final exploration rate
  max_grad_norm: 10                                    # Default: 10        # Maximum gradient norm
  stats_window_size: 100                               # Default: 100       # Size of the statistics window
  tensorboard_log: "./tensorboard/"                    # Default: null      # Path to the Tensorboard log
  policy_kwargs: null                                  # Default: null      # Policy parameters
  verbose: 2                                           # Default: 0         # Verbosity level
  seed: null                                           # Default: null      # Random seed
  device: "auto"                                       # Default: "auto"    # Device to use

# A2C algorithm configuration section
a2c:
  total_timesteps: 80000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode
  eval_freq: 5000                                      # Frequency of model evaluation (in steps)
  save_freq: 5000                                      # Frequency of model saving (in steps)
  learning_rate: 0.0007                                # Default: 0.0007    # Learning rate
  n_steps: 5                                           # Default: 5         # Number of samples to collect before updating the policy
  gamma: 0.99                                          # Default: 0.99      # Discount factor
  gae_lambda: 1.0                                      # Default: 1.0       # GAE lambda
  ent_coef: 0.0                                        # Default: 0.0       # Entropy coefficient
  vf_coef: 0.5                                         # Default: 0.5       # Value function loss coefficient
  max_grad_norm: 0.5                                   # Default: 0.5       # Maximum gradient norm
  rms_prop_eps: 0.00001                                # Default: 0.00001   # Epsilon value for RMSProp
  use_rms_prop: true                                   # Default: true      # Whether to use the RMSProp optimizer
  use_sde: false                                       # Default: false     # Use State Dependent Exploration
  sde_sample_freq: -1                                  # Default: -1        # Sampling frequency for SDE
  rollout_buffer_class: null                           # Default: null      # Rollout buffer class
  rollout_buffer_kwargs: null                          # Default: null      # Rollout buffer parameters
  normalize_advantage: false                           # Default: false     # Normalize advantage function
  stats_window_size: 100                               # Default: 100       # Size of the statistics window
  tensorboard_log: "./tensorboard/"                    # Default: null      # Path to the Tensorboard log
  policy_kwargs: null                                  # Default: null      # Policy parameters
  verbose: 2                                           # Default: 0         # Verbosity level (0: no output, 1: occasional output, 2: all output)
  seed: null                                           # Default: null      # Random seed
  device: "auto"                                       # Default: "auto"    # Device to use (cpu, cuda, auto)

# DDPG algorithm configuration section
ddpg:
  total_timesteps: 80000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode
  eval_freq: 5000                                      # Frequency of model evaluation (in steps)
  save_freq: 5000                                      # Frequency of model saving (in steps)
  learning_rate: 0.001                                 # Default: 0.001     # Learning rate
  buffer_size: 1000000                                 # Default: 1000000   # Size of the replay buffer
  learning_starts: 100                                 # Default: 100       # Number of steps before learning starts
  batch_size: 256                                      # Default: 256       # Batch size
  tau: 0.005                                           # Default: 0.005     # Coefficient for soft update
  gamma: 0.99                                          # Default: 0.99      # Discount factor
  train_freq: 1                                        # Default: 1         # Frequency of training (in steps)
  gradient_steps: 1                                    # Default: 1         # Number of gradient steps to perform during training
  action_noise: null                                   # Default: null      # Action noise
  replay_buffer_class: null                            # Default: null      # Replay buffer class
  replay_buffer_kwargs: null                           # Default: null      # Replay buffer parameters
  optimize_memory_usage: false                         # Default: false     # Optimize memory usage
  tensorboard_log: "./tensorboard/"                    # Default: null      # Path to the Tensorboard log
  policy_kwargs: null                                  # Default: null      # Policy parameters
  verbose: 2                                           # Default: 0         # Verbosity level
  seed: null                                           # Default: null      # Random seed
  device: "auto"                                       # Default: "auto"    # Device to use

# TD3 algorithm configuration section
td3:
  total_timesteps: 80000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode
  eval_freq: 5000                                      # Frequency of model evaluation (in steps)
  save_freq: 5000                                      # Frequency of model saving (in steps)
  learning_rate: 0.001                                 # Default: 0.001     # Learning rate
  buffer_size: 1000000                                 # Default: 1000000   # Size of the replay buffer
  learning_starts: 100                                 # Default: 100       # Number of steps before learning starts
  batch_size: 256                                      # Default: 256       # Batch size
  tau: 0.005                                           # Default: 0.005     # Coefficient for soft update
  gamma: 0.99                                          # Default: 0.99      # Discount factor
  train_freq: 1                                        # Default: 1         # Frequency of training (in steps)
  gradient_steps: 1                                    # Default: 1         # Number of gradient steps to perform during training
  action_noise: null                                   # Default: null      # Action noise
  replay_buffer_class: null                            # Default: null      # Replay buffer class
  replay_buffer_kwargs: null                           # Default: null      # Replay buffer parameters
  optimize_memory_usage: false                         # Default: false     # Optimize memory usage
  policy_delay: 2                                      # Default: 2         # Policy delay
  target_policy_noise: 0.2                             # Default: 0.2       # Target policy noise
  target_noise_clip: 0.5                               # Default: 0.5       # Target noise clipping
  stats_window_size: 100                               # Default: 100       # Size of the statistics window
  tensorboard_log: "./tensorboard/"                    # Default: null      # Path to the Tensorboard log
  policy_kwargs: null                                  # Default: null      # Policy parameters
  verbose: 2                                           # Default: 0         # Verbosity level
  seed: null                                           # Default: null      # Random seed
  device: "auto"                                       # Default: "auto"    # Device to use

# TRPO algorithm configuration section
trpo:
  total_timesteps: 80000                               # Total number of timesteps during training
  episode_max_steps: 500                               # Maximum number of steps per episode
  eval_freq: 5000                                      # Frequency of model evaluation (in steps)
  save_freq: 5000                                      # Frequency of model saving (in steps)
  learning_rate: 0.001                                 # Default: 0.001    # Learning rate
  n_steps: 2048                                        # Default: 2048     # Number of samples to collect before updating the policy
  batch_size: 128                                      # Default: 128      # Batch size
  gamma: 0.99                                          # Default: 0.99     # Discount factor
  cg_max_steps: 15                                     # Default: 15       # Maximum number of iterations for conjugate gradient
  cg_damping: 0.1                                      # Default: 0.1      # Damping factor for conjugate gradient
  line_search_shrinking_factor: 0.8                    # Default: 0.8      # Shrinking factor for line search
  line_search_max_iter: 10                             # Default: 10       # Maximum number of iterations for line search
  n_critic_updates: 10                                 # Default: 10       # Number of critic updates
  gae_lambda: 0.95                                     # Default: 0.95     # GAE lambda
  use_sde: false                                       # Default: false    # Use State Dependent Exploration
  sde_sample_freq: -1                                  # Default: -1       # Sampling frequency for SDE
  rollout_buffer_class: null                           # Default: null     # Rollout buffer class
  rollout_buffer_kwargs: null                          # Default: null     # Rollout buffer parameters
  normalize_advantage: true                            # Default: true     # Normalize advantage function
  target_kl: 0.01                                      # Default: 0.01     # Target KL divergence
  sub_sampling_factor: 1                               # Default: 1        # Sub-sampling factor
  stats_window_size: 100                               # Default: 100      # Size of the statistics window
  tensorboard_log: "./tensorboard/"                    # Default: null     # Path to the Tensorboard log
  policy_kwargs: null                                  # Default: null     # Policy parameters
  verbose: 2                                           # Default: 0        # Verbosity level (0: no output, 1: occasional output, 2: all output)
  seed: null                                           # Default: null     # Random seed
  device: "auto"                                       # Default: "auto"   # Device to use (cpu, cuda, auto)
